Albert:
Fold 1/5
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 1: Epoch 1/100: 100%|███████████████████████████████| 4200/4200 [30:53<00:00,  2.27it/s, lr=1e-6, train_loss=0.297]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.8985119047619048
F1-score: 0.8982119041717497
Precision score: 0.898088474986891
Recall score: 0.8985119047619048
Train and validation losses: 0.8095823855840024, 0.354321597438483
=> Saving checkpoint
Fold 1: Epoch 2/100: 100%|███████████████████████████████| 4200/4200 [30:52<00:00,  2.27it/s, lr=1e-6, train_loss=0.499]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9219047619047619
F1-score: 0.9219380016843175
Precision score: 0.9221553510546112
Recall score: 0.9219047619047619
Train and validation losses: 0.2867826994734683, 0.25076424085135973
=> Saving checkpoint
Fold 1: Epoch 3/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.363]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9320238095238095
F1-score: 0.9323201327732168
Precision score: 0.932932701973144
Recall score: 0.9320238095238096
Train and validation losses: 0.21367729759531184, 0.2167668990994848
=> Saving checkpoint
Fold 1: Epoch 4/100: 100%|██████████████████████████████| 4200/4200 [30:52<00:00,  2.27it/s, lr=1e-6, train_loss=0.0907]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9332738095238096
F1-score: 0.9331612547836095
Precision score: 0.9339084731414671
Recall score: 0.9332738095238096
Train and validation losses: 0.17890214597761986, 0.2109291192569903
=> Saving checkpoint
Fold 1: Epoch 5/100: 100%|███████████████████████████████| 4200/4200 [30:54<00:00,  2.26it/s, lr=1e-6, train_loss=0.067]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9361309523809523
F1-score: 0.9361649125745412
Precision score: 0.936700183966167
Recall score: 0.9361309523809523
Train and validation losses: 0.15511777236159624, 0.20261565274780705
=> Saving checkpoint
Fold 1: Epoch 6/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.284]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9350595238095238
F1-score: 0.9349829718345404
Precision score: 0.9353186644805057
Recall score: 0.9350595238095238
Train and validation losses: 0.1347633509039657, 0.20280782768990668
Fold 1: Epoch 7/100: 100%|███████████████████████████████| 4200/4200 [30:52<00:00,  2.27it/s, lr=1e-6, train_loss=0.293]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.93625
F1-score: 0.9362379832358811
Precision score: 0.9362739420052525
Recall score: 0.93625
Train and validation losses: 0.11488583865348205, 0.20174332551658153
=> Saving checkpoint
Fold 1: Epoch 8/100: 100%|██████████████████████████████| 4200/4200 [30:54<00:00,  2.26it/s, lr=1e-6, train_loss=0.0448]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.934702380952381
F1-score: 0.9346816166484437
Precision score: 0.9349422040476163
Recall score: 0.9347023809523808
Train and validation losses: 0.09630194806504906, 0.21342979506035115
Fold 1: Epoch 9/100: 100%|█████████████████████████████| 4200/4200 [30:53<00:00,  2.27it/s, lr=1e-6, train_loss=0.00991]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.28it/s]
Accuracy: 0.9342261904761905
F1-score: 0.9343100220694219
Precision score: 0.9344991224399765
Recall score: 0.9342261904761905
Train and validation losses: 0.07922109619553555, 0.21987706832055534
Fold 1: Epoch 10/100: 100%|████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.00518]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9323214285714285
F1-score: 0.9324796680979166
Precision score: 0.9331735715673325
Recall score: 0.9323214285714286
Train and validation losses: 0.062220998091867104, 0.2365612735730108
Early stopping at epoch 10
Fold 1: Train losses per epoch: [0.8095823855840024, 0.2867826994734683, 0.21367729759531184, 0.17890214597761986, 0.15511777236159624, 0.1347633509039657, 0.11488583865348205, 0.09630194806504906, 0.07922109619553555, 0.062220998091867104]
Fold 1: Valid losses per epoch: [0.354321597438483, 0.25076424085135973, 0.2167668990994848, 0.2109291192569903, 0.20261565274780705, 0.20280782768990668, 0.20174332551658153, 0.21342979506035115, 0.21987706832055534, 0.2365612735730108]
Fold 2/5
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 2: Epoch 1/100: 100%|███████████████████████████████| 4200/4200 [30:55<00:00,  2.26it/s, lr=1e-6, train_loss=0.107]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9076785714285714
F1-score: 0.9075922132535709
Precision score: 0.9077636811001183
Recall score: 0.9076785714285714
Train and validation losses: 0.7430292702537208, 0.31929012060520195
=> Saving checkpoint
Fold 2: Epoch 2/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.126]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9232738095238096
F1-score: 0.9231187192655044
Precision score: 0.9233381012536013
Recall score: 0.9232738095238096
Train and validation losses: 0.26897306212578853, 0.2503544267249249
=> Saving checkpoint
Fold 2: Epoch 3/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.228]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9300595238095238
F1-score: 0.9302155657269381
Precision score: 0.9308105156657417
Recall score: 0.9300595238095238
Train and validation losses: 0.21511096103316438, 0.22553289216721342
=> Saving checkpoint
Fold 2: Epoch 4/100: 100%|██████████████████████████████| 4200/4200 [30:52<00:00,  2.27it/s, lr=1e-6, train_loss=0.0891]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9318452380952381
F1-score: 0.9320855907443129
Precision score: 0.9330135154424376
Recall score: 0.9318452380952381
Train and validation losses: 0.1846802846938815, 0.21519166876694987
=> Saving checkpoint
Fold 2: Epoch 5/100: 100%|████████████████████████████████| 4200/4200 [30:57<00:00,  2.26it/s, lr=1e-6, train_loss=0.65]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.934047619047619
F1-score: 0.9345170539844174
Precision score: 0.9358218560372652
Recall score: 0.9340476190476191
Train and validation losses: 0.1604045023601724, 0.2066557714644642
=> Saving checkpoint
Fold 2: Epoch 6/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.035]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9361904761904762
F1-score: 0.9360537848206324
Precision score: 0.9362553462034233
Recall score: 0.9361904761904762
Train and validation losses: 0.13931639274471394, 0.20175454231245177
=> Saving checkpoint
Fold 2: Epoch 7/100: 100%|██████████████████████████████| 4200/4200 [30:53<00:00,  2.27it/s, lr=1e-6, train_loss=0.0154]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9358928571428572
F1-score: 0.9360728151710014
Precision score: 0.9363762802744955
Recall score: 0.9358928571428571
Train and validation losses: 0.11956434003897898, 0.20574730317640516
Fold 2: Epoch 8/100: 100%|██████████████████████████████| 4200/4200 [30:53<00:00,  2.27it/s, lr=1e-6, train_loss=0.0491]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.25it/s]
Accuracy: 0.9342857142857143
F1-score: 0.9344199872501167
Precision score: 0.9347967301897947
Recall score: 0.9342857142857143
Train and validation losses: 0.10098349782333355, 0.21165766680080975
Fold 2: Epoch 9/100: 100%|██████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.0579]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9350595238095238
F1-score: 0.9352011659343449
Precision score: 0.935583610593594
Recall score: 0.9350595238095237
Train and validation losses: 0.08180145937605716, 0.21763235425155256
Early stopping at epoch 9
Fold 2: Train losses per epoch: [0.7430292702537208, 0.26897306212578853, 0.21511096103316438, 0.1846802846938815, 0.1604045023601724, 0.13931639274471394, 0.11956434003897898, 0.10098349782333355, 0.08180145937605716]
Fold 2: Valid losses per epoch: [0.31929012060520195, 0.2503544267249249, 0.22553289216721342, 0.21519166876694987, 0.2066557714644642, 0.20175454231245177, 0.20574730317640516, 0.21165766680080975, 0.21763235425155256]
Fold 3/5
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 3: Epoch 1/100: 100%|██████████████████████████████| 4200/4200 [30:54<00:00,  2.27it/s, lr=1e-6, train_loss=0.0934]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.25it/s]
Accuracy: 0.9064285714285715
F1-score: 0.9062325219236124
Precision score: 0.9066957209178667
Recall score: 0.9064285714285715
Train and validation losses: 0.8254290297201702, 0.3398478341954095
=> Saving checkpoint
Fold 3: Epoch 2/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.116]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.925952380952381
F1-score: 0.9258536405085899
Precision score: 0.9259612166569188
Recall score: 0.925952380952381
Train and validation losses: 0.2720256510554325, 0.244512139766344
=> Saving checkpoint
Fold 3: Epoch 3/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.173]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.28it/s]
Accuracy: 0.9324404761904762
F1-score: 0.93248469705303
Precision score: 0.932561389195583
Recall score: 0.9324404761904762
Train and validation losses: 0.20962649989984042, 0.21557638846692584
=> Saving checkpoint
Fold 3: Epoch 4/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.236]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9329761904761905
F1-score: 0.9327349611012036
Precision score: 0.9331341024262212
Recall score: 0.9329761904761904
Train and validation losses: 0.17686289900847313, 0.21394222517808278
=> Saving checkpoint
Fold 3: Epoch 5/100: 100%|██████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.0344]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9326785714285715
F1-score: 0.9330920487436565
Precision score: 0.9347211834693827
Recall score: 0.9326785714285715
Train and validation losses: 0.152297420836209, 0.21135207958386412
=> Saving checkpoint
Fold 3: Epoch 6/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.135]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9372619047619047
F1-score: 0.9373518499150055
Precision score: 0.9375689228078902
Recall score: 0.9372619047619049
Train and validation losses: 0.13210222697328952, 0.1978479347369146
=> Saving checkpoint
Fold 3: Epoch 7/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.013]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9378571428571428
F1-score: 0.9377525384076731
Precision score: 0.9379493623149616
Recall score: 0.937857142857143
Train and validation losses: 0.1102080612996083, 0.20582003387578188
Fold 3: Epoch 8/100: 100%|████████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.11]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9355357142857142
F1-score: 0.9355801631495693
Precision score: 0.9359054553681965
Recall score: 0.9355357142857142
Train and validation losses: 0.09115344979988765, 0.21378295431113137
Fold 3: Epoch 9/100: 100%|██████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.0313]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.28it/s]
Accuracy: 0.9366071428571429
F1-score: 0.9367030981112242
Precision score: 0.9368845171889039
Recall score: 0.9366071428571429
Train and validation losses: 0.07319448698178999, 0.22080358744155437
Early stopping at epoch 9
Fold 3: Train losses per epoch: [0.8254290297201702, 0.2720256510554325, 0.20962649989984042, 0.17686289900847313, 0.152297420836209, 0.13210222697328952, 0.1102080612996083, 0.09115344979988765, 0.07319448698178999]
Fold 3: Valid losses per epoch: [0.3398478341954095, 0.244512139766344, 0.21557638846692584, 0.21394222517808278, 0.21135207958386412, 0.1978479347369146, 0.20582003387578188, 0.21378295431113137, 0.22080358744155437]
Fold 4/5
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 4: Epoch 1/100: 100%|███████████████████████████████| 4200/4200 [30:49<00:00,  2.27it/s, lr=1e-6, train_loss=0.427]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.909345238095238
F1-score: 0.9091757705800921
Precision score: 0.9091532119107957
Recall score: 0.909345238095238
Train and validation losses: 0.7916943368954318, 0.32034937489600407
=> Saving checkpoint
Fold 4: Epoch 2/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.166]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9242261904761905
F1-score: 0.9241620948093555
Precision score: 0.9244924464300547
Recall score: 0.9242261904761904
Train and validation losses: 0.272651692085589, 0.24791343256298984
=> Saving checkpoint
Fold 4: Epoch 3/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.724]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9299404761904762
F1-score: 0.9298965397383329
Precision score: 0.9306173615186429
Recall score: 0.9299404761904763
Train and validation losses: 0.21340378853004602, 0.2214708278168525
=> Saving checkpoint
Fold 4: Epoch 4/100: 100%|████████████████████████████████| 4200/4200 [30:49<00:00,  2.27it/s, lr=1e-6, train_loss=0.17]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9327380952380953
F1-score: 0.9332667671267416
Precision score: 0.9353131082028153
Recall score: 0.9327380952380951
Train and validation losses: 0.1807675537533526, 0.20981261258412684
=> Saving checkpoint
Fold 4: Epoch 5/100: 100%|██████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.0852]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9371428571428572
F1-score: 0.9369919916680965
Precision score: 0.9369523833668831
Recall score: 0.937142857142857
Train and validation losses: 0.15581574666369263, 0.19318793961157402
=> Saving checkpoint
Fold 4: Epoch 6/100: 100%|███████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.117]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.93625
F1-score: 0.9362383945133065
Precision score: 0.936777120802831
Recall score: 0.9362500000000001
Train and validation losses: 0.13316893726675993, 0.19626296409361418
Fold 4: Epoch 7/100: 100%|███████████████████████████████| 4200/4200 [30:49<00:00,  2.27it/s, lr=1e-6, train_loss=0.196]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9374404761904762
F1-score: 0.9375180891233005
Precision score: 0.9378522857072074
Recall score: 0.9374404761904762
Train and validation losses: 0.11189711600586418, 0.20021188500603396
Fold 4: Epoch 8/100: 100%|██████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.0346]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.25it/s]
Accuracy: 0.9357738095238095
F1-score: 0.9358708168682038
Precision score: 0.9367270105353774
Recall score: 0.9357738095238096
Train and validation losses: 0.09276213269325949, 0.21160282818999673
Early stopping at epoch 8
Fold 4: Train losses per epoch: [0.7916943368954318, 0.272651692085589, 0.21340378853004602, 0.1807675537533526, 0.15581574666369263, 0.13316893726675993, 0.11189711600586418, 0.09276213269325949]
Fold 4: Valid losses per epoch: [0.32034937489600407, 0.24791343256298984, 0.2214708278168525, 0.20981261258412684, 0.19318793961157402, 0.19626296409361418, 0.20021188500603396, 0.21160282818999673]
Fold 5/5
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 5: Epoch 1/100: 100%|████████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.64]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9098214285714286
F1-score: 0.9102692427046819
Precision score: 0.9115834686783675
Recall score: 0.9098214285714287
Train and validation losses: 0.7842517805986461, 0.3162667266279459
=> Saving checkpoint
Fold 5: Epoch 2/100: 100%|████████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.22]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9279761904761905
F1-score: 0.9277811071159417
Precision score: 0.9278353647975006
Recall score: 0.9279761904761905
Train and validation losses: 0.2647172046674504, 0.23859316134914046
=> Saving checkpoint
Fold 5: Epoch 3/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.132]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.934047619047619
F1-score: 0.9342322203783258
Precision score: 0.9345976006581378
Recall score: 0.934047619047619
Train and validation losses: 0.2088299141935117, 0.21239974173584156
=> Saving checkpoint
Fold 5: Epoch 4/100: 100%|██████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.0411]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9373809523809524
F1-score: 0.9370788209360861
Precision score: 0.9372028610629128
Recall score: 0.9373809523809523
Train and validation losses: 0.17847539670987145, 0.20483261158778554
=> Saving checkpoint
Fold 5: Epoch 5/100: 100%|███████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.375]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.28it/s]
Accuracy: 0.9414285714285714
F1-score: 0.9415170984463811
Precision score: 0.9417241186500481
Recall score: 0.9414285714285714
Train and validation losses: 0.15506113821596262, 0.18928577906585164
=> Saving checkpoint
Fold 5: Epoch 6/100: 100%|████████████████████████████████| 4200/4200 [30:49<00:00,  2.27it/s, lr=1e-6, train_loss=0.29]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9404761904761905
F1-score: 0.9406062567431893
Precision score: 0.9408652657879102
Recall score: 0.9404761904761905
Train and validation losses: 0.13442470669968143, 0.19452857171939242
Fold 5: Epoch 7/100: 100%|██████████████████████████████| 4200/4200 [30:51<00:00,  2.27it/s, lr=1e-6, train_loss=0.0661]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.26it/s]
Accuracy: 0.9405357142857143
F1-score: 0.9408319339077348
Precision score: 0.9415510335050141
Recall score: 0.9405357142857144
Train and validation losses: 0.1223914798114094, 0.19777110100457712
Fold 5: Epoch 8/100: 100%|█████████████████████████████| 4200/4200 [30:50<00:00,  2.27it/s, lr=1e-6, train_loss=0.00715]
Evaluating validation dataset of 16800 instances: 100%|█████████████████████████████| 1050/1050 [02:24<00:00,  7.27it/s]
Accuracy: 0.9380357142857143
F1-score: 0.9381403685488537
Precision score: 0.9386621160001027
Recall score: 0.9380357142857143
Train and validation losses: 0.10581390132717344, 0.20393080933307786
Early stopping at epoch 8
Fold 5: Train losses per epoch: [0.7842517805986461, 0.2647172046674504, 0.2088299141935117, 0.17847539670987145, 0.15506113821596262, 0.13442470669968143, 0.1223914798114094, 0.10581390132717344]
Fold 5: Valid losses per epoch: [0.3162667266279459, 0.23859316134914046, 0.21239974173584156, 0.20483261158778554, 0.18928577906585164, 0.19452857171939242, 0.19777110100457712, 0.20393080933307786]
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
=> Loading checkpoint
Fold 1: Evaluating test dataset of 21000 instances: 100%|███████████████████████████| 1313/1313 [02:59<00:00,  7.30it/s]
['Control' 'adhd' 'anxiety' 'bipolar' 'cptsd' 'depression' 'schizophrenia']
Fold 1: Accuracy: 0.9381904761904762
[0.981      0.97233333 0.92333333 0.90933333 0.944      0.89133333
 0.946     ]
Fold 1: F1-score: 0.9381543332295509
Fold 1: F1-score: [0.98428094 0.9646164  0.92164365 0.91405596 0.94305694 0.89326875
 0.94615769]
Precision: 0.9381481027321217
Precision: [0.98758389 0.957021   0.91996015 0.91882789 0.94211577 0.89521259
 0.94631544]
Recall: 0.9381904761904762
Recall: [0.981      0.97233333 0.92333333 0.90933333 0.944      0.89133333
 0.946     ]
=> Loading checkpoint
Fold 2: Evaluating test dataset of 21000 instances: 100%|███████████████████████████| 1313/1313 [02:59<00:00,  7.30it/s]
['Control' 'adhd' 'anxiety' 'bipolar' 'cptsd' 'depression' 'schizophrenia']
Fold 2: Accuracy: 0.9371904761904762
[0.98066667 0.969      0.90666667 0.90366667 0.95566667 0.87733333
 0.96733333]
Fold 2: F1-score: 0.9370306405499226
Fold 2: F1-score: [0.98378198 0.96851574 0.92078538 0.91141368 0.94698596 0.89024184
 0.9374899 ]
Precision: 0.9372892477785646
Precision: [0.98691714 0.96803197 0.93535076 0.91929468 0.93846154 0.90353587
 0.90943278]
Recall: 0.9371904761904762
Recall: [0.98066667 0.969      0.90666667 0.90366667 0.95566667 0.87733333
 0.96733333]
=> Loading checkpoint
Fold 3: Evaluating test dataset of 21000 instances: 100%|███████████████████████████| 1313/1313 [02:59<00:00,  7.30it/s]
['Control' 'adhd' 'anxiety' 'bipolar' 'cptsd' 'depression' 'schizophrenia']
Fold 3: Accuracy: 0.940047619047619
[0.98333333 0.96866667 0.933      0.89366667 0.94733333 0.904
 0.95033333]
Fold 3: F1-score: 0.9401063625245693
Fold 3: F1-score: [0.98612736 0.96947456 0.9234576  0.91345826 0.95081967 0.89195856
 0.94544852]
Precision: 0.9403792858012924
Precision: [0.98893731 0.97028381 0.91410843 0.93414634 0.95433177 0.88023369
 0.94061366]
Recall: 0.940047619047619
Recall: [0.98333333 0.96866667 0.933      0.89366667 0.94733333 0.904
 0.95033333]
=> Loading checkpoint
Fold 4: Evaluating test dataset of 21000 instances: 100%|███████████████████████████| 1313/1313 [03:00<00:00,  7.29it/s]
['Control' 'adhd' 'anxiety' 'bipolar' 'cptsd' 'depression' 'schizophrenia']
Fold 4: Accuracy: 0.9368571428571428
[0.98666667 0.97466667 0.92933333 0.90533333 0.94966667 0.87533333
 0.937     ]
Fold 4: F1-score: 0.9366976315227188
Fold 4: F1-score: [0.98404255 0.96837225 0.92211014 0.90623957 0.94619728 0.8919837
 0.93793794]
Precision: 0.9366639472424269
Precision: [0.98143236 0.9621586  0.91499836 0.90714763 0.94275314 0.90927978
 0.93887776]
Recall: 0.9368571428571429
Recall: [0.98666667 0.97466667 0.92933333 0.90533333 0.94966667 0.87533333
 0.937     ]
=> Loading checkpoint
Fold 5: Evaluating test dataset of 21000 instances: 100%|███████████████████████████| 1313/1313 [02:59<00:00,  7.30it/s]
['Control' 'adhd' 'anxiety' 'bipolar' 'cptsd' 'depression' 'schizophrenia']
Fold 5: Accuracy: 0.9383333333333334
[0.98166667 0.97133333 0.92733333 0.89233333 0.94266667 0.90533333
 0.94766667]
Fold 5: F1-score: 0.9383951335874018
Fold 5: F1-score: [0.98346969 0.97036297 0.9222609  0.90915266 0.94883409 0.89063781
 0.94404782]
Precision: 0.9386409643195555
Precision: [0.98527936 0.96939454 0.91724365 0.92661821 0.95508274 0.87641175
 0.9404565 ]
Recall: 0.9383333333333334
Recall: [0.98166667 0.97133333 0.92733333 0.89233333 0.94266667 0.90533333
 0.94766667]
['Control' 'adhd' 'anxiety' 'bipolar' 'cptsd' 'depression' 'schizophrenia']
Cross Validation Accuracy: 0.9446190476190476
[0.98533333 0.978      0.93233333 0.90833333 0.95033333 0.90166667
 0.95633333]
Cross Validation F1-score: 0.9445651066194316
Cross Validation F1-score: [0.98648423 0.97458894 0.93016295 0.91905565 0.95017497 0.90211773
 0.94937128]
Cross Validation Precision: 0.9445674209861846
Cross Validation Precision: [0.98763782 0.97120159 0.92800265 0.93003413 0.95001666 0.90256924
 0.94250986]
Cross Validation Recall: 0.9446190476190476
Cross Validation Recall: [0.98533333 0.978      0.93233333 0.90833333 0.95033333 0.90166667
 0.95633333]
Trained Albert model in 88910.9067 seconds
